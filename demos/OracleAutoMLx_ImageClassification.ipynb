{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd65766e",
   "metadata": {},
   "source": [
    "***\n",
    "# <font color=red>Building an Image Classifier using AutoMLx</font>\n",
    "<p style=\"margin-left:10%; margin-right:10%;\">by the <font color=teal> Oracle AutoMLx Team </font></p>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16b827b",
   "metadata": {},
   "source": [
    "Image Classification Demo Notebook.\n",
    "\n",
    "Copyright © 2023, Oracle and/or its affiliates.\n",
    "\n",
    "Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23abf665",
   "metadata": {},
   "source": [
    "## Overview of this Notebook\n",
    "\n",
    "In this notebook we will build a image classifier using the Oracle AutoMLx tool for the public PneumoniaMNIST dataset which is part of MedMNIST datasets. The dataset is a multi-label classification dataset, and more details about the dataset can be found at https://medmnist.com/.\n",
    "We explore the various options provided by the Oracle AutoMLx tool, allowing the user to exercise control over the AutoML training process. We then evaluate the different models trained by AutoML.\n",
    "\n",
    "---\n",
    "## Prerequisites\n",
    "\n",
    "  - Experience level: Novice (Python and Machine Learning)\n",
    "  - Professional experience: Some industry experience\n",
    "---\n",
    "\n",
    "## Business Use\n",
    "\n",
    "Data analytics and modeling problems using Machine Learning (ML) are becoming popular and often rely on data science expertise to build accurate ML models. Such modeling tasks primarily involve the following steps:\n",
    "- Pick an appropriate model for the given dataset and prediction task at hand.\n",
    "- Tune the chosen model’s hyperparameters for the given dataset.\n",
    "\n",
    "All of these steps are significantly time consuming and heavily rely on data scientist expertise. Unfortunately, to make this problem harder, the best model, and hyperparameter choice widely varies with the dataset and the prediction task. Hence, there is no one-size-fits-all solution to achieve reasonably good model performance. Using a simple Python API, AutoMLx can quickly jump-start the datascience process with an accurately-tuned model for a given prediction task.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- <a href='#setup'>Setup</a>\n",
    "- <a href='#load-data'>Load the PneumoniaMNIST dataset</a>\n",
    "- <a href='#AutoML'>AutoML</a>\n",
    "  - <a href='#Engine'>Setting the execution engine</a>\n",
    "  - <a href='#provider'>Create an Instance of Oracle AutoMLx</a>\n",
    "  - <a href='#default'>Train a Model using AutoML</a>\n",
    "  - <a href='#analyze'>Analyze the AutoML optimization process </a>\n",
    "      - <a href='#algorithm-selection'>Algorithm Selection</a>\n",
    "      - <a href='#adaptive-sampling'>Adaptive Sampling</a>\n",
    "      - <a href='#model-tuning'>Model Tuning</a>\n",
    "      - <a href='#confusion-matrix'>Confusion Matrix</a>\n",
    "  - <a href='#advanced'> Advanced AutoML Configuration </a>\n",
    "- <a href='#ref'>References</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8822a8",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## Setup\n",
    "\n",
    "Basic setup for the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87329532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773b4d75",
   "metadata": {},
   "source": [
    "Load the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546fe15",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Settings for plots\n",
    "plt.rcParams['figure.figsize'] = [4, 3]\n",
    "plt.rcParams['font.size'] = 15\n",
    "\n",
    "import automlx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6977fbdc",
   "metadata": {},
   "source": [
    "<a id='load-data'></a>\n",
    "## Load the PneumoniaMNIST dataset\n",
    "We start by reading in the dataset from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db929306",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"albertvillanova/medmnist-v2\", \"pneumoniamnist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce4374",
   "metadata": {},
   "source": [
    "Lets look at a few of the values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04e97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7f319a",
   "metadata": {},
   "source": [
    "Plot one of the images as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74867af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pneumonia\" if dataset[\"train\"][0]['label'] == 1 else 'Normal')\n",
    "dataset[\"train\"][0]['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915e47c",
   "metadata": {},
   "source": [
    "We visualize the distribution of the target variable in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f767fd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(dataset[\"train\"][\"label\"])\n",
    "y_df.columns = ['label']\n",
    "\n",
    "fig = px.histogram(y_df[\"label\"].apply(lambda x: \"Normal\" if x == 0 else \"Pneumonia\"), x=\"label\", barmode=\"group\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff0bba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "We now separate the predictions (`y`) from the training data (`X`) for both the training (70%) and test (30%) datasets. The training set will be used to create a Machine Learning model using AutoML, and the test set will be used to evaluate the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb6dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(dataset[\"train\"][\"image\"], columns=['images'])\n",
    "y = pd.DataFrame(dataset[\"train\"][\"label\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=0)\n",
    "\n",
    "# reducing the number of samples in training set to speed up the demo\n",
    "X_train = X_train[:1000]\n",
    "y_train = y_train[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec89b83",
   "metadata": {},
   "source": [
    "<a id='AutoML'></a>\n",
    "## AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915786ea",
   "metadata": {},
   "source": [
    "<a id='provider'></a>\n",
    "### Create an instance of Oracle AutoMLx\n",
    "\n",
    "The Oracle AutoMLx solution provides a pipeline that automatically finds a tuned model given a prediction task and a training dataset.\n",
    "\n",
    "AutoML consists of three main steps for image classification:\n",
    "- **Algorithm Selection** : Identify the right classification algorithm for a given dataset.\n",
    "- **Adaptive Sampling** : Select a subset of the data samples for the model to be trained on.\n",
    "- **Model Tuning** : Find the right model parameters (including model size) that maximize score for the given dataset.\n",
    "\n",
    "All these pieces are readily combined into a simple AutoML pipeline which automates the entire Machine Learning process with minimal user input/interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b390f304",
   "metadata": {},
   "source": [
    "<a id='default'></a>\n",
    "### Train a model using AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a71006",
   "metadata": {},
   "source": [
    "The AutoMLx API is quite simple to work with. We create an instance of the pipeline. Next, the training data is passed to the `fit()` function which executes the previously mentioned steps.\n",
    "Note that we decreased number of tuning trials in Model Tuning, to speed up the demo notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aec7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "est1 = automlx.Pipeline(task='classification', max_tuning_trials=10, score_metric=\"balanced_accuracy\")\n",
    "est1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01789c7",
   "metadata": {},
   "source": [
    "A model is then generated (`est1`) and can be used for prediction tasks. We use the `balanced accuracy` scoring metric to evaluate the performance of this model on unseen data (`X_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e4e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = est1.predict(X_test)\n",
    "score_default = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Score on test data : {score_default:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd538eb",
   "metadata": {},
   "source": [
    "<a id='analyze'></a>\n",
    "### Analyze the AutoML optimization process\n",
    "\n",
    "During the AutoML process, a summary of the optimization process is logged. It consists of:\n",
    "- Information about the training data .\n",
    "- Information about the AutoML, such as:\n",
    "    - Selected algorithm that was the best choice for this data;\n",
    "    - Selected hyperparameters for the selected algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed063a4d",
   "metadata": {},
   "source": [
    "AutoMLx provides a `print_summary` API to output all the different trials performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f13ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "est1.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e3ec93",
   "metadata": {},
   "source": [
    "We also provide the capability to visualize the results of each stage of the AutoML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763052d",
   "metadata": {},
   "source": [
    "<a id='algorithm-selection'></a>\n",
    "#### Algorithm Selection\n",
    "\n",
    "The plot below shows the scores predicted by Algorithm Selection for each algorithm. The horizontal line shows the average score across all algorithms. Algorithms below the line are colored turquoise, whereas those with a score higher than the mean are colored teal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc81d8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Each trial is a row in a dataframe that contains\n",
    "# Algorithm, Number of Samples, Number of Features, Hyperparameters, Score, Runtime, Memory Usage, Step as features\n",
    "trials = est1.completed_trials_summary_[est1.completed_trials_summary_[\"Step\"].str.contains('Model Selection')]\n",
    "name_of_score_column = f\"Score ({est1._inferred_score_metric[0].name})\"\n",
    "trials.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "trials.dropna(subset=[name_of_score_column],inplace=True)\n",
    "colors = []\n",
    "scores = trials[name_of_score_column].tolist()\n",
    "models = trials['Algorithm'].tolist()\n",
    "y_margin = 0.10 * (max(scores) - min(scores))\n",
    "s = pd.Series(scores, index=models).sort_values(ascending=False)\n",
    "s = s.dropna()\n",
    "for f in s.keys():\n",
    "    if f.strip()  ==  est1.selected_model_.strip():\n",
    "        colors.append('orange')\n",
    "    elif s[f] >= s.mean():\n",
    "        colors.append('teal')\n",
    "    else:\n",
    "        colors.append('turquoise')\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_title(\"Algorithm Selection Trials\")\n",
    "ax.set_ylim(min(scores) - y_margin, max(scores) + y_margin)\n",
    "ax.set_ylabel(est1._inferred_score_metric[0].name)\n",
    "s.plot.bar(ax=ax, color=colors, edgecolor='black')\n",
    "ax.axhline(y=s.mean(), color='black', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c3d330",
   "metadata": {},
   "source": [
    "<a id='model-tuning'></a>\n",
    "#### Model Tuning\n",
    "\n",
    "Model Tuning is the last stage of AutoML, and focuses on improving the chosen algorithm's score on the reduced dataset (after Adaptive Sampling). AutoML uses a novel algorithm to search across many hyperparameters dimensions, and converge automatically when optimal hyperparameters are identified. Each trial represents a particular hyperparameters configuration for the selected model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a253d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each trial is a row in a dataframe that contains\n",
    "# Algorithm, Number of Samples, Number of Features, Hyperparameters, Score, Runtime, Memory Usage, Step as features\n",
    "trials = est1.completed_trials_summary_[est1.completed_trials_summary_[\"Step\"].str.contains('Model Tuning')]\n",
    "trials.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "trials.dropna(subset=[name_of_score_column], inplace=True)\n",
    "trials = trials.sort_values(by=['Finished'],ascending=True)\n",
    "scores = trials[name_of_score_column].tolist()\n",
    "score = []\n",
    "score.append(scores[0])\n",
    "for i in range(1,len(scores)):\n",
    "    if scores[i]>= score[i-1]:\n",
    "        score.append(scores[i])\n",
    "    else:\n",
    "        score.append(score[i-1])\n",
    "y_margin = 0.10 * (max(score) - min(score))\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_title(\"Model Tuning Trials\")\n",
    "ax.set_xlabel(\"Iteration $n$\")\n",
    "ax.set_ylabel(est1._inferred_score_metric[0].name)\n",
    "ax.grid(color='g', linestyle='-', linewidth=0.1)\n",
    "ax.set_ylim(min(score) - y_margin, max(score) + y_margin)\n",
    "ax.plot(range(1, len(trials) + 1), score, 'k:', marker=\"s\", color='teal', markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ac25f",
   "metadata": {},
   "source": [
    "<a id='advanced'></a>\n",
    "### Advanced AutoML Configuration\n",
    "\n",
    "For customizing the model tuning step, the range of the hyperparameters of each of the models can be specified and passed to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_hyperparameters = {\n",
    "    \"epochs\": {'range': [1,5],\n",
    "               'type': 'discrete'\n",
    "              },\n",
    "    \"batch_size\": {'range': [16, 32],\n",
    "                   'type': 'discrete'\n",
    "                  }\n",
    "}\n",
    "search_space = {\n",
    "    \"ResNet\" : {\n",
    "        \"size\": {'range': [\"18\",\"101\"],\n",
    "                 'type': 'categorical'\n",
    "                },\n",
    "        **shared_hyperparameters\n",
    "\n",
    "    },\n",
    "         \"EfficientNet\" : {\n",
    "        \"size\": {'range': [\"b2\",\"b6\"],\n",
    "                 'type': 'categorical'\n",
    "                },\n",
    "        **shared_hyperparameters\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de41a2eb",
   "metadata": {},
   "source": [
    "You can also configure the pipeline with suitable parameters according to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32530f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pipeline = automlx.Pipeline(\n",
    "    task='classification',\n",
    "    model_list=[                 # Specify the models you want the AutoML to consider\n",
    "        'ResNet',\n",
    "        'EfficientNet',\n",
    "    ],\n",
    "    n_algos_tuned=2,             # Choose how many models to tune\n",
    "    adaptive_sampling=False,     # Disable or enable Adaptive Sampling step. Default to `True`\n",
    "    search_space=search_space,   # You can specify the hyper-parameters and ranges AutoML searches\n",
    "    max_tuning_trials=2,         # The maximum number of tuning trials. Can be integer or Dict (max number for each model)\n",
    "    score_metric='f1_macro',     # Any scikit-learn metric or a custom function\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70f1484",
   "metadata": {},
   "source": [
    "A few of the advanced settings can be passed directly to the pipeline's fit method, instead of its constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pipeline.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    time_budget= 20,    # Specify time budget in seconds\n",
    "    cv='auto'           # Automatically pick a good cross-validation (cv) strategy for the user's dataset.\n",
    "                        # Ignored if X_valid and y_valid are provided.\n",
    "                        # Can also be:\n",
    "                        #   - An integer (for example, to use 5-fold cross validation)\n",
    "                        #   - A list of data indices to use as splits (for advanced, such as time-based splitting)\n",
    ")\n",
    "y_pred = custom_pipeline.predict(X_test)\n",
    "score_default = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Score on test data : {score_default:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7488dc0",
   "metadata": {},
   "source": [
    "<a id='ref'></a>\n",
    "## References\n",
    "* Oracle AutoML http://www.vldb.org/pvldb/vol13/p3166-yakovlev.pdf\n",
    "* scikit-learn https://scikit-learn.org/stable/\n",
    "* Hugging Face https://huggingface.co/\n",
    "* MedMNIST Dataset https://medmnist.com/"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
